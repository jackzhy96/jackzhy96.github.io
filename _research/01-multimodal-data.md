---
title: "Multi-Modal Data Collection and Analysis for Surgical Robotics"
excerpt: "Multi-Modal Time-Synchronized Data Collection and Post-Processing Framework for Surgical Robotics, along with datasets and AI-driven applications (stay tuned!)"
collection: research
order: 1
year: 2024
year_end: 2026
venue: "Johns Hopkins University"
location: "Baltimore, MD"
tags:
  - Surgical Robotics
  - dVRK
  - Dataset Pipeline
  - Deep Learning
  - Multi-Modal
  - Computer Vision
  - System Integration
  - Synchronized Data Collection
publication_only: true

# Add your image or GIF here:
teaser: "research/surgsync_dataset_overview.png"

# Publications associated with this research
publications:
  - title: "SurgSync: Time-Synchronized Multi-modal Data Collection Framework and Dataset for Surgical Robotics"
    authors: "Zhou, H.*, Liu, C.*, Wu, Y., ..., & Kazanzides, P."
    venue: "IEEE Intl. Conf. on Robotics and Automation (ICRA)"
    year: 2026
    submit_year: 2025
    arxiv_url: "coming_soon"
    website_url: "coming_soon"
    code_url: "coming_soon"
    dataset_url: "coming_soon"
    under_review: true
---

## Overview

This research represents Multi-Modal Time-Synchronized Data Collection and Post-Processing Framework for Surgical Robotics, along with datasets and AI-driven applications (stay tuned!).

<figure>
  <img src="/images/research/surgsync_dataset_overview.png" alt="Description" style="width: 85%">
  <figcaption>SurgSync Overview</figcaption>
</figure>

## Key Contributions
- Lead and manage 8-person cross-functional team, delivering IRB-compliant data collection and analysis that accelerated publication timeline and demo readiness
- Build time-synchronized (multi-modality sync time latency within 10ms) multi-modal data collection pipeline (vision + kinematics + sensor) and large (100+ instances) ex-vivo dataset
- Enable a novel kinematic projection approach and downstream optical flow/depth estimation using deep learning
- Design and implement a custom capacitive contact sensor to acquire the ground truth of tool-tissue contact
- Integrate a modern endoscope with the dVRK seamlessly, enabling high-quality image data acquisition
- Design a novel data annotation application with graphic user interface (GUI) using PyQt for manual label annotations
- The data collection pipeline has been employed for efforts on Open-H-Embodiment

## Future/Ongoing Work
- Investigate surgical robot tool-tissue contact detection using a multi-modal deep learning approach.


<!-- Add your media content below -->
<!-- Example for adding an image: -->
<!-- ![Research Overview](/images/research/multimodal-contact.png) -->


<!-- Example for adding a GIF: -->
<!-- ![Demo GIF](/images/research/multimodal-contact-demo.gif) -->
